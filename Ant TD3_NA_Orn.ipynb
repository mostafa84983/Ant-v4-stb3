{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines3 import TD3\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_path = os.path.join('Logs')\n",
    "models_path = os.path.join('Models')\n",
    "Ant_TD3_NA_path = os.path.join(models_path,'Ant_Model_TD3_NA')\n",
    "Ant_TD3_Orn_path = os.path.join(models_path,'Ant_Model_TD3_Orn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Ant-v4\", render_mode=\"rgb_array\")\n",
    "\n",
    "# The noise objects for TD3\n",
    "n_actions = env.action_space.shape[-1]\n",
    "# action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "action_noise = OrnsteinUhlenbeckActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "\n",
    "# Evaluate the model frequantly and stop at satisfactory reward\n",
    "stop_train_callback = StopTrainingOnRewardThreshold(reward_threshold=3000, verbose=1)\n",
    "eval_callback = EvalCallback(eval_env=env, eval_freq=30_000, callback_after_eval=stop_train_callback, best_model_save_path=Ant_TD3_NA_path, verbose=1)\n",
    "\n",
    "# Initialize the model\n",
    "model = TD3(\"MlpPolicy\", env, action_noise=action_noise, verbose=1, tensorboard_log=os.path.join(logs_path,'Final Logs'))\n",
    "model.learn(total_timesteps=int(1e6), log_interval=10, callback =eval_callback)\n",
    "\n",
    "del model # remove to demonstrate saving and loading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Movements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "\n",
      "Starting < Random Movements >\n",
      "Episode: 0 Score: [6.629386]\n",
      "Episode: 1 Score: [-2.8597863]\n",
      "Episode: 2 Score: [-79.52603]\n",
      "Episode: 3 Score: [-58.251022]\n",
      "Episode: 4 Score: [-10.662735]\n",
      "Mean Score for 5 episodes: [-28.934036]\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "total_score = 0\n",
    "\n",
    "render = True\n",
    "render_frequency = 1\n",
    "\n",
    "env = gym.make(\"Ant-v4\", render_mode='rgb_array')\n",
    "model = TD3.load(os.path.join(Ant_TD3_NA_path,'best_model'), env)\n",
    "vec_env = model.get_env()\n",
    "\n",
    "print(f'\\nStarting < Random Movements >')\n",
    "for episode in range(episodes):\n",
    "    obs = vec_env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    frame_count = 0\n",
    "    \n",
    "    while not done:\n",
    "        action = [vec_env.action_space.sample()]\n",
    "        obs, rewards, done, _ = vec_env.step(action)\n",
    "        score += rewards\n",
    "        if render:\n",
    "            if frame_count % render_frequency == 0:\n",
    "                vec_env.render('human')\n",
    "            frame_count += 1\n",
    "    \n",
    "    total_score += score\n",
    "    print(f'Episode: {episode} Score: {score}')\n",
    "\n",
    "print(f'Mean Score for {episode + 1} episodes: {total_score / episodes}')\n",
    "env.close()\n",
    "vec_env.close()\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trained Movements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting < Ant_Model_TD3_Orn >\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Episode: 1 Score: [3085.0332]\n",
      "For model < Ant_Model_TD3_Orn >\n",
      "Mean Score for 1 episodes: [3085.0332]\n"
     ]
    }
   ],
   "source": [
    "episodes = 1\n",
    "\n",
    "render = True\n",
    "render_frequency = 1\n",
    "\n",
    "env = gym.make(\"Ant-v4\", render_mode='rgb_array')\n",
    "# models_to_try = [Ant_TD3_NA_path, Ant_TD3_Orn_path]\n",
    "models_to_try = [Ant_TD3_Orn_path]\n",
    "\n",
    "for current_model in models_to_try:\n",
    "    \n",
    "    print(f'\\nStarting < {current_model.removeprefix(os.path.join(models_path,\"\"))} >')\n",
    "    model = TD3.load(os.path.join(current_model,'best_model'), env=env)\n",
    "    vec_env = model.get_env()\n",
    "    total_score = 0\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        obs = vec_env.reset()\n",
    "        done = False\n",
    "        score = 0\n",
    "        frame_count = 0\n",
    "        \n",
    "        while not done:\n",
    "            action, _ = model.predict(obs)\n",
    "            obs, rewards, done, info = vec_env.step(action)\n",
    "            score += rewards\n",
    "            if render:\n",
    "                if frame_count % render_frequency == 0:\n",
    "                    vec_env.render('human')\n",
    "            frame_count += 1\n",
    "        \n",
    "        total_score += score\n",
    "        print(f'Episode: {episode + 1} Score: {score}')\n",
    "    \n",
    "    print(f'For model < {current_model.removeprefix(os.path.join(models_path,\"\"))} >')\n",
    "    print(f'Mean Score for {episode + 1} episodes: {total_score / episodes}')\n",
    "\n",
    "env.close()    \n",
    "vec_env.close()\n",
    "del model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
